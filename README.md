## üéØ Objetivo do Sistema

Ensinar Matem√°tica de forma adaptativa e personalizada para alunos do Ensino Fundamental 2, usando BNCC. Permitir atividades desplugadas, com suporte digital opcional para monitoramento e feedback. Gerar tutoria inteligente usando IA generativa para criar exerc√≠cios, problemas contextualizados, dicas, explica√ß√µes passo a passo e avalia√ß√µes.

## üß© Funcionalidades Principais

### Gera√ß√£o de Conte√∫do Inteligente

- Exerc√≠cios matem√°ticos adaptados ao n√≠vel do aluno
- Problemas contextualizados com temas do dia a dia
- Explica√ß√µes passo a passo com linguagem simples

### Monitoramento do Aprendizado

- Registro de desempenho por t√≥pico ou habilidade
- Sugest√£o de revis√µes para pontos fracos

### Feedback Interativo

- Feedback positivo e corretivo automatizado
- Recomenda√ß√µes personalizadas de exerc√≠cios

### Modo Desplugado

- Impress√£o de materiais gerados
- Atividades offline para execu√ß√£o em sala ou em casa

### Suporte a Professores

- Planejamento de aulas com base no desempenho da turma
- Relat√≥rios detalhados de progresso

## üõ†Ô∏è Tecnologias Utilizadas

- **Frontend**: Flutter (app multiplataforma) - funciona em Web, Desktop, Mobile
- **IA Generativa**: SmartAI Service com fallback autom√°tico:
  - üñ•Ô∏è **Ollama Local**: Processamento no PC do usu√°rio (offline, privado)
  - ‚òÅÔ∏è **Google Gemini**: Processamento na nuvem (sempre dispon√≠vel)
- **Hospedagem**: GitHub Pages (funciona mesmo conectando ao Ollama local)

### üöÄ Como Funciona a IA H√≠brida

A aplica√ß√£o tenta conectar ao **Ollama rodando no PC local** primeiro. Se n√£o estiver dispon√≠vel, automaticamente usa o **Google Gemini** na nuvem. Isso oferece:

- ‚úÖ **Melhor Performance**: Ollama local √© mais r√°pido
- ‚úÖ **Privacidade**: Dados ficam no PC quando usa Ollama
- ‚úÖ **Disponibilidade**: Sempre funciona com Gemini como fallback
- ‚úÖ **Funciona no GitHub Pages**: Mesmo hospedado estaticamente

### üìã Para Usar Ollama Local (Opcional)

1. **Instalar Ollama**: `winget install Ollama.Ollama`
2. **Configurar CORS** (PowerShell como administrador):
   ```powershell
   [Environment]::SetEnvironmentVariable("OLLAMA_ORIGINS", "*", "Machine")
   ```
3. **Instalar um modelo**: `ollama pull llama3.2`
4. **Pronto!** A aplica√ß√£o detectar√° automaticamente

Se n√£o configurar o Ollama, funciona perfeitamente com Gemini! üéâ

## üåü Benef√≠cios do Sistema

- Personaliza√ß√£o do ensino de Matem√°tica
- Possibilidade de uso em locais com baixa conectividade
- Redu√ß√£o de carga para professores, automatizando sugest√µes e exerc√≠cios
- Est√≠mulo √† aprendizagem ativa e desplugada, mantendo o engajamento dos alunos
